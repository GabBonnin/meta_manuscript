{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# META transcription\n",
        "\n",
        "Gabriel Bonnin"
      ],
      "id": "b60851f6-9ede-47d6-8709-b2a79395a957"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt\n",
        "\n",
        "# Für eventuellen Grafikkarten-Support:\n",
        "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
      ],
      "id": "cell-1"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple GPU (Metal) erkannt – Whisper läuft auf der GPU."
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# === Device Setup ===\n",
        "if torch.backends.mps.is_available():  # Apple GPU (Metal)\n",
        "    device = \"mps\"\n",
        "    print(\"Apple GPU (Metal) erkannt – Whisper läuft auf der GPU.\")\n",
        "elif torch.cuda.is_available():  # NVIDIA GPU\n",
        "    device = \"cuda\"\n",
        "    print(f\"NVIDIA GPU erkannt ({torch.cuda.get_device_name(0)}) – Whisper läuft auf der GPU.\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Keine GPU erkannt – Whisper läuft auf dem CPU.\")\n",
        "\n",
        "# === Pfade ===\n",
        "load_dotenv()\n",
        "data_root = os.getenv(\"DATA_ROOT\")\n",
        "raw_audio_path = os.path.join(data_root, \"raw/raw_audio\")   # hier lagen die eingesprochenen Dateien\n",
        "processed_path = os.path.join(data_root, \"processed/processed_transcriptions\")  # hier werden die CSV mit den transkribierten Daten, sowie ein Log-File gespeichern\n",
        "os.makedirs(processed_path, exist_ok=True)\n",
        "\n",
        "processed_log_path = os.path.join(processed_path, \"processed_log.txt\")\n",
        "output_csv = os.path.join(processed_path, \"Transcriptions.csv\")\n",
        "\n",
        "if data_root is None:\n",
        "    raise EnvironmentError(\"DATA_ROOT ist nicht gesetzt! Bitte .env anlegen.\")\n",
        "\n",
        "# === Whisper Modell Set-Up ===\n",
        "model_name = \"large-v2\"  # Je nach GPU Speichergröße bzw. Gerät auf dem der Code läuft. Auswahlmöglichkeiten: \"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\""
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import whisper\n",
        "import torch\n",
        "import librosa\n",
        "from rapidfuzz import process, fuzz\n",
        "\n",
        "# === Helper: bereits verarbeitete Dateien laden ===\n",
        "processed_files = set()\n",
        "if os.path.exists(processed_log_path):\n",
        "    with open(processed_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            path = line.strip()\n",
        "            if path:\n",
        "                path = os.path.abspath(path).replace(\"\\\\\", \"/\")  # Normalisieren\n",
        "                processed_files.add(path)\n",
        "\n",
        "# === GPU Cache leeren (falls nötig) ===\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# === Whisper-Modell laden auf passendem Device ===\n",
        "model = whisper.load_model(model_name)\n",
        "\n",
        "# === NATO-Alphabet ===\n",
        "NATO_CANON = {\n",
        "    \"alpha\": \"A\", \"bravo\": \"B\", \"charlie\": \"C\", \"delta\": \"D\", \"echo\": \"E\",\n",
        "    \"foxtrot\": \"F\", \"golf\": \"G\", \"hotel\": \"H\", \"india\": \"I\", \"juliett\": \"J\",\n",
        "    \"kilo\": \"K\", \"lima\": \"L\", \"mike\": \"M\", \"november\": \"N\", \"oscar\": \"O\",\n",
        "    \"papa\": \"P\", \"quebec\": \"Q\", \"romeo\": \"R\", \"sierra\": \"S\", \"tango\": \"T\",\n",
        "    \"uniform\": \"U\", \"victor\": \"V\", \"whiskey\": \"W\", \"xray\": \"X\", \"yankee\": \"Y\", \"zulu\": \"Z\"\n",
        "}\n",
        "\n",
        "# Häufige Varianten/ASR-Fehler -> canonical key\n",
        "NATO_ALIASES = {\n",
        "    \"whisky\": \"whiskey\",\n",
        "    \"juliet\": \"juliett\",\n",
        "    \"x-ray\": \"xray\",\n",
        "    \"x ray\": \"xray\",\n",
        "    \"xray\": \"xray\",\n",
        "    \"alfa\": \"alpha\",       \n",
        "    \"sulu\": \"zulu\",        \n",
        "    \"zoulou\": \"zulu\", \n",
        "    \"oskar\": \"oscar\",\n",
        "    \"maik\": \"mike\",\n",
        "    \"meik\": \"mike\",\n",
        "    \"mic\": \"mike\",     \n",
        "}\n",
        "\n",
        "NATO_KEYS = list(NATO_CANON.keys())\n",
        "\n",
        "def normalize_nato_word(raw: str, min_score: int = 85):\n",
        "    \"\"\"\n",
        "    Normalisiert ein transkribiertes NATO-Wort auf einen canonical key (z.B. 'whiskey' -> 'whisky').\n",
        "    Fällt zurück auf fuzzy matching, wenn kein Alias passt.\n",
        "    \"\"\"\n",
        "    if not raw:\n",
        "        return None\n",
        "\n",
        "    w = raw.lower().strip()\n",
        "    # Nur Buchstaben/Leerzeichen/Bindestrich behalten (für x-ray, x ray, etc.)\n",
        "    w = re.sub(r\"[^a-z\\- ]+\", \"\", w)\n",
        "    w = re.sub(r\"\\s+\", \" \", w).strip()\n",
        "\n",
        "    # 1) Harte Aliases\n",
        "    if w in NATO_ALIASES:\n",
        "        w = NATO_ALIASES[w]\n",
        "        return w\n",
        "\n",
        "    # 2) Direkt korrekt\n",
        "    if w in NATO_CANON:\n",
        "        return w\n",
        "\n",
        "    # 3) Fuzzy Matching\n",
        "    match = process.extractOne(w, NATO_KEYS, scorer=fuzz.WRatio)\n",
        "    if match and match[1] >= min_score:\n",
        "        return match[0]\n",
        "\n",
        "    return None\n",
        "\n",
        "# A) Zahlwörter für Fragenummern\n",
        "NUM_WORDS_Q = {\n",
        "    # 0-19\n",
        "    \"null\": \"0\",\n",
        "    \"eins\": \"1\",\n",
        "    \"zwei\": \"2\",\n",
        "    \"drei\": \"3\",\n",
        "    \"vier\": \"4\",\n",
        "    \"fünf\": \"5\",\n",
        "    \"sechs\": \"6\",\n",
        "    \"sieben\": \"7\",\n",
        "    \"acht\": \"8\",\n",
        "    \"neun\": \"9\",\n",
        "    \"zehn\": \"10\",\n",
        "    \"elf\": \"11\",\n",
        "    \"zwölf\": \"12\",\n",
        "    \"dreizehn\": \"13\",\n",
        "    \"sechzig\": \"60\",\n",
        "    \"einundsechzig\": \"61\",\n",
        "    \"zweiundsechzig\": \"62\",\n",
        "}\n",
        "\n",
        "# B) Zahlwörter für Code-Ziffernfolgen: nur 0-9 (damit du nicht ungewollt Fließtext veränderst)\n",
        "NUM_WORDS_DIGITS = {\n",
        "    \"null\": \"0\",\n",
        "    \"eins\": \"1\",\n",
        "    \"zwei\": \"2\",\n",
        "    \"drei\": \"3\",\n",
        "    \"vier\": \"4\",\n",
        "    \"fünf\": \"5\",\n",
        "    \"sechs\": \"6\",\n",
        "    \"sieben\": \"7\",\n",
        "    \"acht\": \"8\",\n",
        "    \"neun\": \"9\",\n",
        "}\n",
        "\n",
        "def normalize_question_numbers_de(t: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalisiert 'Frage <zahlwort>' -> 'Frage <zahl>' (inkl. bis 62).\n",
        "    \"\"\"\n",
        "    # z.B. \"Frage Nummer fünf\" / \"Frage Nr. fünf\" / \"Frage fünf\"\n",
        "    pattern = re.compile(r'(?i)\\bFrage(?:\\s+Nr\\.?|\\s+Nummer)?\\s+([A-Za-zäöüÄÖÜß]+)\\b')\n",
        "\n",
        "    def repl(m):\n",
        "        w = m.group(1).lower()\n",
        "        return f\"Frage {NUM_WORDS_Q.get(w, w)}\"\n",
        "\n",
        "    return pattern.sub(repl, t)\n",
        "\n",
        "def normalize_digit_sequences_de(t: str) -> str:\n",
        "    \"\"\"\n",
        "    Ersetzt isolierte Zahlwörter 0-9 durch Ziffern.\n",
        "    Das hilft v.a. bei 6-stelligen Code-Folgen, die als 'eins zwei drei ...' eingesprochen werden.\n",
        "    \"\"\"\n",
        "    keys = sorted(NUM_WORDS_DIGITS.keys(), key=len, reverse=True)\n",
        "    pattern = re.compile(r'(?i)\\b(' + \"|\".join(map(re.escape, keys)) + r')\\b')\n",
        "\n",
        "    def repl(m):\n",
        "        return NUM_WORDS_DIGITS[m.group(1).lower()]\n",
        "\n",
        "    return pattern.sub(repl, t)\n",
        "\n",
        "def normalize_transcript_for_extraction(text: str) -> str:\n",
        "    x = text\n",
        "    x = normalize_question_numbers_de(x)\n",
        "    x = normalize_digit_sequences_de(x)\n",
        "    return x\n",
        "\n",
        "# === Erwartete Fragen ===\n",
        "expected_markers = [\n",
        "    \"Frage 5\", \"Frage 6\", \"Frage 7\", \"Frage 8\", \"Frage 9\", \n",
        "    \"Frage 10\", \"Frage 11\", \"Frage 12\", \"Frage 13\", \n",
        "    \"Frage 40\", \"Frage 60\", \"Frage 61\", \"Frage 62\"\n",
        "]\n",
        "\n",
        "def clean_answer(answer: str) -> str:\n",
        "    answer = re.sub(r'(?i)^\\s*hier folgt die antwort auf\\s*', '', answer)\n",
        "    answer = re.sub(r'(?i)\\s*hier folgt die antwort auf\\s*$', '', answer)\n",
        "    return answer.strip(\" .,-\")\n",
        "\n",
        "def robust_extract_questions(text: str, expected_markers: list) -> dict:\n",
        "    marker_pattern = re.compile(r'(Frage\\s*\\d+)', re.IGNORECASE)\n",
        "    matches = list(marker_pattern.finditer(text))\n",
        "    answers = {marker: None for marker in expected_markers}\n",
        "\n",
        "    def normalize_marker(m):\n",
        "        return re.sub(r'\\s+', ' ', m.group()).strip().capitalize()\n",
        "    \n",
        "    extracted = []\n",
        "    for i, m in enumerate(matches):\n",
        "        marker_text = normalize_marker(m)\n",
        "        start_index = m.end()\n",
        "        end_index = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
        "        extracted.append((marker_text, start_index, end_index))\n",
        "\n",
        "    # NEU: kein break -> letzte Version überschreibt frühere\n",
        "    for exp_marker in expected_markers:\n",
        "        for marker_text, start, end in extracted:\n",
        "            if marker_text.lower() == exp_marker.lower():\n",
        "                answer = clean_answer(text[start:end].strip())\n",
        "                answers[exp_marker] = answer\n",
        "                # kein break -> spätere Treffer überschreiben frühere\n",
        "    return answers\n",
        "\n",
        "# === Alle neuen Audio-Dateien sammeln ===\n",
        "audio_files = []\n",
        "for root, _, files in os.walk(raw_audio_path):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(('.wav', '.mp3', '.m4a', '.flac')) and not f.startswith('._'):\n",
        "            full_path = os.path.abspath(os.path.join(root, f)).replace(\"\\\\\", \"/\")  # Normalisieren\n",
        "            if full_path not in processed_files:\n",
        "                audio_files.append(full_path)\n",
        "\n",
        "print(f\"{len(audio_files)} neue Dateien gefunden.\")\n",
        "\n",
        "# === Falls schon CSV existiert, laden ===\n",
        "if os.path.exists(output_csv):\n",
        "    df = pd.read_csv(output_csv)\n",
        "    data = df.to_dict(\"records\")\n",
        "else:\n",
        "    data = []\n",
        "\n",
        "# === Neue Dateien verarbeiten ===\n",
        "for audio_path in audio_files:\n",
        "    audio_path = os.path.abspath(audio_path).replace(\"\\\\\", \"/\")\n",
        "\n",
        "    # print(f\"Processing: {audio_path}\")  # Un-kommentieren, um Pfad sichtbar zu machen\n",
        "\n",
        "    # --- Transkription: WAV direkt mit librosa laden ---\n",
        "    audio, sr = librosa.load(audio_path, sr=16000)  # resample auf 16 kHz\n",
        "    result = model.transcribe(audio, language=\"de\")\n",
        "    text = result['text']\n",
        "\n",
        "    # --- Normalisierung für robuste Extraktion (Zahlwörter etc.)\n",
        "    text_norm = normalize_transcript_for_extraction(text)\n",
        "\n",
        "    # --- Chiffre-Extraktion robust (NATO Aliases + Fuzzy)\n",
        "\n",
        "    # NATO-Wort (auch x-ray / x ray) + 6 Ziffern (mit Leerzeichen/Kommas erlaubt)\n",
        "    code_match = re.search(r'\\b([A-Za-zÄÖÜäöüß\\- ]+?)\\s*[:;,]?\\s*([0-9][0-9\\s,\\.\\-\\/]{4,}[0-9])\\b', text_norm)\n",
        "    code = None\n",
        "    if code_match:\n",
        "        nato_raw = code_match.group(1)\n",
        "        digit_blob = code_match.group(2)\n",
        "\n",
        "        # Alle Nicht-Ziffern raus => nur digits\n",
        "        digits = re.sub(r'\\D+', '', digit_blob)\n",
        "\n",
        "        nato_norm = normalize_nato_word(nato_raw)\n",
        "        if nato_norm and len(digits) == 6:\n",
        "            code = f\"{NATO_CANON[nato_norm]}{digits}\"\n",
        "\n",
        "    # --- Fragen-Extraktion (auf normalisiertem Text) ---\n",
        "    question_answers = robust_extract_questions(text_norm, expected_markers)\n",
        "    # Ergebnis speichern\n",
        "    entry = {\"file_path\": audio_path, \"code\": code, \"full_transcript\": text}\n",
        "    entry.update({f\"q{m.split()[1]}\": question_answers.get(m) for m in expected_markers})\n",
        "    data.append(entry)\n",
        "\n",
        "    # --- CSV aktualisieren ---\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    # --- Log aktualisieren ---\n",
        "    with open(processed_log_path, \"a\", encoding=\"utf-8\") as log:\n",
        "        log.write(audio_path + \"\\n\")\n",
        "\n",
        "# === Abschlussmeldung ===\n",
        "print(\"Fertig mit der Verarbeitung aller neuen Dateien.\")"
      ],
      "id": "cell-3"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "meta_transcription_kernel",
      "display_name": "meta_transcription_kernel",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  }
}