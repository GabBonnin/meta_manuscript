{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# META transcription\n",
        "\n",
        "Gabriel Bonnin"
      ],
      "id": "eab12ea3-a63c-4644-89d3-b20af96a9318"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install -r requirements.txt\n",
        "\n",
        "# Für eventuellen Grafikkarten-Support:\n",
        "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
      ],
      "id": "cell-1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# === Device Setup ===\n",
        "if torch.backends.mps.is_available():  # Apple GPU (Metal)\n",
        "    device = \"mps\"\n",
        "    print(\"Apple GPU (Metal) erkannt – Whisper läuft auf der GPU.\")\n",
        "elif torch.cuda.is_available():  # NVIDIA GPU\n",
        "    device = \"cuda\"\n",
        "    print(f\"NVIDIA GPU erkannt ({torch.cuda.get_device_name(0)}) – Whisper läuft auf der GPU.\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"Keine GPU erkannt – Whisper läuft auf dem CPU.\")\n",
        "\n",
        "# === Pfade ===\n",
        "load_dotenv()\n",
        "data_root = os.getenv(\"DATA_ROOT\")\n",
        "raw_audio_path = os.path.join(data_root, \"raw/raw_audio\")   # hier lagen die eingesprochenen Dateien\n",
        "processed_path = os.path.join(data_root, \"processed/processed_transcriptions\")  # hier werden die CSV mit den transkribierten Daten, sowie ein Log-File gespeichern\n",
        "os.makedirs(processed_path, exist_ok=True)\n",
        "\n",
        "processed_log_path = os.path.join(processed_path, \"processed_log.txt\")\n",
        "output_csv = os.path.join(processed_path, \"Transcriptions.csv\")\n",
        "\n",
        "if data_root is None:\n",
        "    raise EnvironmentError(\"DATA_ROOT ist nicht gesetzt! Bitte .env anlegen.\")\n",
        "\n",
        "# === Whisper Modell Set-Up ===\n",
        "model_name = \"large-v2\"  # Je nach GPU Speichergröße bzw. Gerät auf dem der Code läuft. Auswahlmöglichkeiten: \"tiny\", \"base\", \"small\", \"medium\", \"large\", \"large-v2\", \"large-v3\""
      ],
      "id": "cell-2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import whisper\n",
        "import torch\n",
        "import librosa\n",
        "\n",
        "# === Helper: bereits verarbeitete Dateien laden ===\n",
        "processed_files = set()\n",
        "if os.path.exists(processed_log_path):\n",
        "    with open(processed_log_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            path = line.strip()\n",
        "            if path:\n",
        "                path = os.path.abspath(path).replace(\"\\\\\", \"/\")  # Normalisieren\n",
        "                processed_files.add(path)\n",
        "\n",
        "# === GPU Cache leeren (falls nötig) ===\n",
        "if device == \"cuda\":\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# === Whisper-Modell laden auf passendem Device ===\n",
        "model = whisper.load_model(model_name)\n",
        "\n",
        "# === NATO-Alphabet ===\n",
        "nato_alphabet = {\n",
        "    \"alpha\": \"A\", \"bravo\": \"B\", \"charlie\": \"C\", \"delta\": \"D\", \"echo\": \"E\",\n",
        "    \"foxtrot\": \"F\", \"golf\": \"G\", \"hotel\": \"H\", \"india\": \"I\", \"juliett\": \"J\",\n",
        "    \"kilo\": \"K\", \"lima\": \"L\", \"mike\": \"M\", \"november\": \"N\", \"oscar\": \"O\",\n",
        "    \"papa\": \"P\", \"quebec\": \"Q\", \"romeo\": \"R\", \"sierra\": \"S\", \"tango\": \"T\",\n",
        "    \"uniform\": \"U\", \"victor\": \"V\", \"whiskey\": \"W\", \"xray\": \"X\", \"yankee\": \"Y\", \"zulu\": \"Z\"\n",
        "}\n",
        "\n",
        "# === Erwartete Fragen ===\n",
        "expected_markers = [\n",
        "    \"Frage 5\", \"Frage 6\", \"Frage 7\", \"Frage 8\", \"Frage 9\", \n",
        "    \"Frage 10\", \"Frage 11\", \"Frage 12\", \"Frage 13\", \n",
        "    \"Frage 40\", \"Frage 60\", \"Frage 61\", \"Frage 62\"\n",
        "]\n",
        "\n",
        "def clean_answer(answer: str) -> str:\n",
        "    answer = re.sub(r'(?i)^\\s*hier folgt die antwort auf\\s*', '', answer)\n",
        "    answer = re.sub(r'(?i)\\s*hier folgt die antwort auf\\s*$', '', answer)\n",
        "    return answer.strip(\" .,-\")\n",
        "\n",
        "def robust_extract_questions(text: str, expected_markers: list) -> dict:\n",
        "    marker_pattern = re.compile(r'(Frage\\s*\\d+)', re.IGNORECASE)\n",
        "    matches = list(marker_pattern.finditer(text))\n",
        "    answers = {marker: None for marker in expected_markers}\n",
        "\n",
        "    def normalize_marker(m):\n",
        "        return re.sub(r'\\s+', ' ', m.group()).strip().capitalize()\n",
        "    \n",
        "    extracted = []\n",
        "    for i, m in enumerate(matches):\n",
        "        marker_text = normalize_marker(m)\n",
        "        start_index = m.end()\n",
        "        end_index = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
        "        extracted.append((marker_text, start_index, end_index))\n",
        "\n",
        "    # NEU: kein break -> letzte Version überschreibt frühere\n",
        "    for exp_marker in expected_markers:\n",
        "        for marker_text, start, end in extracted:\n",
        "            if marker_text.lower() == exp_marker.lower():\n",
        "                answer = clean_answer(text[start:end].strip())\n",
        "                answers[exp_marker] = answer\n",
        "                # kein break -> spätere Treffer überschreiben frühere\n",
        "    return answers\n",
        "\n",
        "# === Alle neuen Audio-Dateien sammeln ===\n",
        "audio_files = []\n",
        "for root, _, files in os.walk(raw_audio_path):\n",
        "    for f in files:\n",
        "        if f.lower().endswith(('.wav', '.mp3', '.m4a', '.flac')) and not f.startswith('._'):\n",
        "            full_path = os.path.abspath(os.path.join(root, f)).replace(\"\\\\\", \"/\")  # Normalisieren\n",
        "            if full_path not in processed_files:\n",
        "                audio_files.append(full_path)\n",
        "\n",
        "print(f\"{len(audio_files)} neue Dateien gefunden.\")\n",
        "\n",
        "# === Falls schon CSV existiert, laden ===\n",
        "if os.path.exists(output_csv):\n",
        "    df = pd.read_csv(output_csv)\n",
        "    data = df.to_dict(\"records\")\n",
        "else:\n",
        "    data = []\n",
        "\n",
        "# === Neue Dateien verarbeiten ===\n",
        "for audio_path in audio_files:\n",
        "    audio_path = os.path.abspath(audio_path).replace(\"\\\\\", \"/\")\n",
        "\n",
        "    # print(f\"Processing: {audio_path}\")  # Un-kommentieren, um Pfad sichtbar zu machen\n",
        "\n",
        "    # --- Transkription: WAV direkt mit librosa laden ---\n",
        "    audio, sr = librosa.load(audio_path, sr=16000)  # resample auf 16 kHz\n",
        "    result = model.transcribe(audio, language=\"de\")\n",
        "    text = result['text']\n",
        "\n",
        "    # --- Chiffre-Extraktion ---\n",
        "    code_match = re.search(r'\\b([A-Za-z]+)[\\s:,-]*((?:\\d[\\s,]*){6})\\b', text)\n",
        "    code = None\n",
        "    if code_match:\n",
        "        nato_word = code_match.group(1).lower()\n",
        "        digits = re.sub(r'[\\s,]+', '', code_match.group(2))\n",
        "        if len(digits) == 6 and nato_word in nato_alphabet:\n",
        "            code = f\"{nato_alphabet[nato_word]}{digits}\"\n",
        "\n",
        "    # --- Fragen-Extraktion ---\n",
        "    question_answers = robust_extract_questions(text, expected_markers)\n",
        "\n",
        "    # Ergebnis speichern\n",
        "    entry = {\"file_path\": audio_path, \"code\": code, \"full_transcript\": text}\n",
        "    entry.update({f\"q{m.split()[1]}\": question_answers.get(m) for m in expected_markers})\n",
        "    data.append(entry)\n",
        "\n",
        "    # --- CSV aktualisieren ---\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
        "\n",
        "    # --- Log aktualisieren ---\n",
        "    with open(processed_log_path, \"a\", encoding=\"utf-8\") as log:\n",
        "        log.write(audio_path + \"\\n\")\n",
        "\n",
        "# === Abschlussmeldung ===\n",
        "print(\"Fertig mit der Verarbeitung aller neuen Dateien.\")"
      ],
      "id": "cell-3"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "meta_transcription_kernel",
      "display_name": "meta_transcription_kernel",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  }
}