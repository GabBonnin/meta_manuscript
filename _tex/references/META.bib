@article{10.1111/j.2517-6161.1996.tb02080.x,
  title = {Regression Shrinkage and Selection via the Lasso},
  author = {Tibshirani, Robert},
  year = {1996},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {58},
  number = {1},
  eprint = {https://academic.oup.com/jrsssb/article-pdf/58/1/267/49098631/jrsssb{\textbackslash}\_58{\textbackslash}\_1{\textbackslash}\_267.pdf},
  pages = {267--288},
  issn = {0035-9246},
  doi = {10.1111/j.2517-6161.1996.tb02080.x},
  abstract = {We propose a new method for estimation in linear models. The `lasso' minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.}
}

@article{10.5555/944919.944937,
  title = {Latent Dirichlet Allocation},
  author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.},
  year = {2003},
  month = mar,
  journal = {Journal of Machine Learning Research},
  volume = {3},
  number = {null},
  pages = {993--1022},
  publisher = {JMLR.org},
  issn = {1532-4435},
  abstract = {We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.},
  issue_date = {3/1/2003},
  file = {/Users/gabrielbonnin/Zotero/storage/RZ2HRQSC/Blei et al. - 2003 - Latent dirichlet allocation.pdf}
}

@inproceedings{598994,
  title = {Random Decision Forests},
  booktitle = {Proceedings of 3rd International Conference on Document Analysis and Recognition},
  author = {Ho, Tin Kam},
  year = {1995},
  volume = {1},
  pages = {278-282 vol.1},
  doi = {10.1109/ICDAR.1995.598994},
  keywords = {Classification tree analysis,Decision trees,Handwriting recognition,Hidden Markov models,Multilayer perceptrons,Optimization methods,Stochastic processes,Testing,Tin,Training data}
}

@book{Beck1996,
  title = {{{BDI-II}}: {{Beck Depression Inventory}} Manual},
  author = {Beck, A. T. and Steer, R. A. and Brown, G. K.},
  year = {1996},
  edition = {2nd ed.},
  publisher = {Psychological Corporation},
  address = {San Antonio}
}

@article{Bonnin2024,
  title = {How {{Happy Is Happy Enough}}? {{A Cross-Cultural Comparison}} of {{Optimal Cut Points}} for the {{Positive Mental Health Scale}}},
  author = {Bonnin, Gabriel and Hirschfeld, Gerrit and {von Brachel}, Ruth and Margraf, J{\"u}rgen},
  year = {2024},
  journal = {European Journal of Psychological Assessment},
  volume = {0},
  number = {0}
}

@incollection{Bonnin2024a,
  title = {Die {{Klassifikation}} Psychischer {{St{\"o}rungen}} Mit Diagnostischen {{Interviews}}},
  booktitle = {Klinische {{Psychologie}} Und {{Psychotherapie}}: {{Ein}} Verfahrens{\"u}bergreifendes {{Lehr-}} Und {{Lernbuch}}},
  author = {Bonnin, Gabriel and Kr{\"o}ber, Svea and von Brachel, Ruth},
  editor = {Teismann, Tobias and Thoma, Patrizia and Taubner, S. and Wannem{\"u}ller, Andre and von Sydow, K.},
  year = {2024},
  publisher = {Hogrefe}
}

@article{chorpita2011evidence,
  title = {Evidence-Based Treatments for Children and Adolescents: {{An}} Updated Review of Indicators of Efficacy and Effectiveness},
  author = {Chorpita, Bruce F and Daleiden, Eric L and Ebesutani, Chad and Young, John and Becker, Kimberly D and Nakamura, Brad J and Phillips, Lisa and Ward, Alyssa and Lynch, Roxanna and Trent, Lindsay and others},
  year = {2011},
  journal = {Clinical Psychology: Science and Practice},
  volume = {18},
  number = {2},
  pages = {154--172},
  publisher = {Wiley Online Library}
}

@inproceedings{devlin-etal-2019-bert,
  title = {{{BERT}}: {{Pre-training}} of Deep Bidirectional Transformers for Language Understanding},
  booktitle = {Proceedings of the 2019 Conference of the North {{American}} Chapter of the Association for Computational Linguistics: {{Human}} Language Technologies, Volume 1 (Long and Short Papers)},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
  year = {2019},
  month = jun,
  pages = {4171--4186},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1423},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).}
}

@misc{grootendorst2022bertopicneuraltopicmodeling,
  title = {{{BERTopic}}: {{Neural}} Topic Modeling with a Class-Based {{TF-IDF}} Procedure},
  author = {Grootendorst, Maarten},
  year = {2022},
  eprint = {2203.05794},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv}
}

@misc{gu_kjell_schwartz_kjell_2024,
  title = {Natural Language Response Formats for Assessing Depression and Worry with Large Language Models: A Sequential Evaluation with Model Pre-Registration},
  author = {Gu, Zhuojun and Kjell, Katarina and Schwartz, H. A and Kjell, Oscar N E},
  year = {2024},
  month = jul,
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/p67db},
  file = {/Users/gabrielbonnin/Zotero/storage/PYXS3WAU/Gu et al. - 2024 - Natural language response formats for assessing de.pdf}
}

@misc{Gu2024,
  title = {Natural {{Language Response Formats}} for {{Assessing Depression}} and {{Worry}} with {{Large Language Models}}: {{A Sequential Evaluation}} with {{Model Pre-registration}}},
  shorttitle = {Natural {{Language Response Formats}} for {{Assessing Depression}} and {{Worry}} with {{Large Language Models}}},
  author = {Gu, Zhuojun and Kjell, Katarina and Schwartz, H. Andrew and Kjell, Oscar Nils Erik},
  year = {2024},
  month = jul,
  doi = {10.31234/osf.io/p67db},
  urldate = {2025-06-02},
  abstract = {Large Language Models can transform individuals' mental health descriptions into scores that correlate with rating scales approaching theoretical upper limits. However, such analyses have combined word- and text-responses with little known about their differences. We develop response formats ranging from closed-ended to open-ended: 1) select words from lists, write 2) descriptive words, 3) phrases, or 4) texts. Participants answered questions about their depression/worry using the response formats and related rating scales. Language responses were transformed into word embeddings and trained to rating scales. We compare the validity (concurrent, incremental, face, discriminant, and external validity) and reliability (prospective sample and test-retest reliability) of the response formats. Using the Sequential Evaluation with Model Pre-registration design, machine-learning models were trained on a development dataset (N=963), and then pre-registered before tested on a prospective sample (N=145). The pre-registered models demonstrate strong validity and reliability, yielding high accuracy in the prospective sample (r=.60--.79). Additionally, the models demonstrated external validity to self-reported sick-leave/healthcare visits, where the text-format yielded the strongest correlations (being higher/equal to rating scales for 9 of 12 cases). The overall high validity and reliability across formats suggest the possibility of choosing formats according to clinical needs.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/QNNW4ZLE/Gu et al. - 2024 - Natural Language Response Formats for Assessing De.pdf}
}

@article{Hoerl1970,
  title = {Ridge {{Regression}}: {{Biased Estimation}} for {{Nonorthogonal Problems}}},
  author = {Hoerl, A. E. and Kennard, R. W.},
  year = {1970},
  journal = {Technometrics},
  volume = {12},
  number = {1},
  pages = {55--67},
  doi = {10.1080/00401706.1970.10488634}
}

@article{info:doi/10.2196/54176,
  title = {A Blended Learning Course on the Diagnostics of Mental Disorders: {{Multicenter}} Cluster Randomized Noninferiority Trial},
  author = {Bonnin, Gabriel and Kr{\"o}ber, Svea and Schneider, Silvia and Margraf, J{\"u}rgen and Pflug, Verena and Gerlach, Alexander L and Slotta, Timo and Christiansen, Hanna and Albrecht, Bj{\"o}rn and Chavanon, Mira-Lynn and Hirschfeld, Gerrit and {In-Albon}, Tina and Thielsch, Meinald T and {von Brachel}, Ruth},
  year = {2024},
  month = nov,
  journal = {Journal of medical Internet research},
  volume = {26},
  pages = {e54176},
  issn = {1438-8871},
  doi = {10.2196/54176},
  abstract = {Background: Clinical diagnoses determine if and how therapists treat their patients. As misdiagnoses can have severe adverse effects, disseminating evidence-based diagnostic skills into clinical practice is highly important. Objective: This study aimed to develop and evaluate a blended learning course in a multicenter cluster randomized controlled trial. Methods: Undergraduate psychology students (N=350) enrolled in 18 university courses at 3 universities. The courses were randomly assigned to blended learning or traditional synchronous teaching. The primary outcome was the participants' performances in a clinical diagnostic interview after the courses. The secondary outcomes were diagnostic knowledge and participants' reactions to the courses. All outcomes were analyzed on the individual participant level using noninferiority testing. Results: Compared with the synchronous course (74.6\% pass rate), participation in the blended learning course (89\% pass rate) increased the likelihood of successfully passing the behavioral test (odds ratio 2.77, 95\% CI 1.55-5.13), indicating not only noninferiority but superiority of the blended learning course. Furthermore, superiority of the blended learning over the synchronous course could be found regarding diagnostic knowledge ({$\beta$}=.13, 95\% CI 0.01-0.26), course clarity ({$\beta$}=.40, 95\% CI 0.27-0.53), course structure ({$\beta$}=.18, 95\% CI 0.04-0.32), and informativeness ({$\beta$}=.19, 95\% CI 0.06-0.32). Conclusions: Blended learning can help to improve the diagnostic skills and knowledge of (future) clinicians and thus make an important contribution to improving mental health care. Trial Registration: ClinicalTrials.gov NCT05294094; https://clinicaltrials.gov/study/NCT05294094},
  keywords = {blended learning,clinical diagnosis,clinical interview,clinical practice,diagnosis,diagnostic test,dissemination,health personnel,mental health,mental health services,psychology students,structured clinical interviews,therapist training}
}

@article{Jensen-Doss2008,
  title = {Diagnostic Agreement Predicts Treatment Process and Outcomes in Youth Mental Health Clinics},
  author = {{Jensen-Doss}, Amanda and Weisz, John R.},
  year = {2008},
  journal = {Journal of Consulting and Clinical Psychology},
  volume = {76},
  number = {5},
  pages = {711--722},
  publisher = {American Psychological Association},
  address = {US},
  issn = {1939-2117},
  doi = {10.1037/0022-006X.76.5.711},
  abstract = {Several studies have documented low rates of agreement between clinician- and researcher-generated diagnoses. However, little is known about whether this lack of agreement has implications for the processes and outcomes of subsequent treatment. To study this possibility, the authors used diagnostic agreement to predict therapy engagement and outcomes for 197 youths treated in 5 community mental health clinics. Diagnostic agreement predicted better therapy engagement, with the agree group having fewer therapy no-shows and cancellations and a decreased likelihood of therapy dropout. Additionally, support for a link between agreement and treatment outcomes was found, as the agree group obtained larger reductions in parent-reported internalizing problems during treatment. These findings suggest that diagnostic accuracy may be an important precursor to successful treatment and highlight the importance of future research to find ways to incorporate standardized diagnostic procedures into clinical care settings. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Diagnosis,Mental Health Services,Psychotherapeutic Processes,Treatment Outcomes},
  file = {/Users/gabrielbonnin/Zotero/storage/CQTN7ERG/2008-13625-001.html}
}

@article{Jobin2019,
  title = {The Global Landscape of {{AI}} Ethics Guidelines},
  author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
  year = {2019},
  month = sep,
  journal = {Nature Machine Intelligence},
  volume = {1},
  number = {9},
  pages = {389--399},
  issn = {2522-5839},
  doi = {10.1038/s42256-019-0088-2},
  urldate = {2025-06-02},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/SJ3ENVMT/Jobin et al. - 2019 - The global landscape of AI ethics guidelines.pdf}
}

@misc{kjell_ganesan_boyd_oltmanns_rivero_feltman_carr_luft_kotov_schwartz_2024,
  title = {Demonstrating High Validity of a New {{AI-language}} Assessment of {{PTSD}}: A Sequential Evaluation with Model Pre-Registration},
  author = {Kjell, Oscar N E and Ganesan, Adithya V and Boyd, Ryan and Oltmanns, Joshua R and Rivero, Alfredo and Feltman, Scott and Carr, Melissa A and Luft, Benjamin J and Kotov, Roman and Schwartz, H. A},
  year = {2024},
  month = oct,
  publisher = {PsyArXiv},
  doi = {10.31234/osf.io/xw24e},
  file = {/Users/gabrielbonnin/Zotero/storage/HK5PDF9D/Kjell et al. - 2024 - Demonstrating high validity of a new AI-language a.pdf}
}

@article{kjell2019semantic,
  title = {Semantic Measures: {{Using}} Natural Language Processing to Measure, Differentiate, and Describe Psychological Constructs.},
  author = {Kjell, Oscar N. E. and Kjell, Katarina and Garcia, Danilo and Sikstr{\"o}m, Sverker},
  year = {2019},
  journal = {Psychological Methods},
  volume = {24},
  number = {1},
  pages = {92--115},
  publisher = {American Psychological Association},
  doi = {10.1037/met0000191},
  file = {/Users/gabrielbonnin/Zotero/storage/WIND8Y58/Kjell et al. - Semantic Measures Using Natural Language Processi.pdf}
}

@article{Kjell2022,
  title = {Natural Language Analyzed with {{AI-based}} Transformers Predict Traditional Subjective Well-Being Measures Approaching the Theoretical Upper Limits in Accuracy},
  author = {Kjell, Oscar N. E. and Sikstr{\"o}m, Sverker and Kjell, Katarina and Schwartz, H. Andrew},
  year = {2022},
  month = mar,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {3918},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-07520-w},
  urldate = {2024-12-19},
  abstract = {Abstract                            We show that using a recent break-through in artificial intelligence --               transformers--               , psychological assessments from text-responses can approach theoretical upper limits in accuracy, converging with standard psychological rating scales. Text-responses use people's primary form of communication --               natural language               -- and have been suggested as a more ecologically-valid response format than closed-ended rating scales that dominate social science. However, previous language analysis techniques left a gap between how accurately they converged with standard rating scales and how well ratings scales converge with themselves -- a theoretical upper-limit in accuracy. Most recently, AI-based language analysis has gone through a transformation as nearly all of its applications, from Web search to personalized assistants (e.g., Alexa and Siri), have shown unprecedented improvement by using transformers. We evaluate transformers for estimating psychological well-being from questionnaire text- and descriptive word-responses, and find accuracies converging with rating scales that approach the theoretical upper limits (Pearson               r               \,=~0.85,               p               \,{$<$}\,0.001,               N               \,=\,608; in line with most metrics of rating scale reliability). These findings suggest an avenue for modernizing the ubiquitous questionnaire and ultimately opening doors to a greater understanding of the human condition.},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/HDSAT7TH/Kjell et al. - 2022 - Natural language analyzed with AI-based transforme.pdf}
}

@article{Kjell2023,
  title = {The Text-Package: {{An R-package}} for Analyzing and Visualizing Human Language Using Natural Language Processing and Transformers.},
  shorttitle = {The Text-Package},
  author = {Kjell, Oscar and Giorgi, Salvatore and Schwartz, H. Andrew},
  year = {2023},
  month = dec,
  journal = {Psychological Methods},
  volume = {28},
  number = {6},
  pages = {1478--1498},
  issn = {1939-1463, 1082-989X},
  doi = {10.1037/met0000542},
  urldate = {2024-12-19},
  abstract = {The language that individuals use for expressing themselves contains rich psychological information. Recent significant advances in Natural Language Processing (NLP) and Deep Learning (DL), namely transformers, have resulted in large performance gains in tasks related to understanding natural language. However, these state-of-the-art methods have not yet been made easily accessible for psychology researchers, nor designed to be optimal for human-level analyses. This tutorial introduces text (https://r-text.org/), a new R-package for analyzing and visualizing human language using transformers, the latest techniques from NLP and DL. The text-package is both a modular solution for accessing state-of-the-art language models and an end-to-end solution catered for human-level analyses. Hence, text provides user-friendly functions tailored to test hypotheses in social sciences for both relatively small and large data sets. The tutorial describes methods for analyzing text, providing functions with reliable defaults that can be used off-the-shelf as well as providing a framework for the advanced users to build on for novel pipelines. The reader learns about three core methods: (1) textEmbed(): to transform text to modern transformer-based word embeddings; (2) textTrain() and textPredict(): to train predictive models with embeddings as input, and use the models to predict from; (3) textSimilarity() and textDistance(): to compute semantic similarity/distance scores between texts. The reader also learns about two extended methods: (1) textProjection()/textProjectionPlot() and (2) textCentrality()/ textCentralityPlot(): to examine and visualize text within the embedding space.},
  copyright = {http://www.apa.org/pubs/journals/resources/open-access.aspx},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/5VK97CHF/Kjell et al. - 2023 - The text-package An R-package for analyzing and v.pdf}
}

@article{Kjell2024,
  title = {Beyond Rating Scales: {{With}} Targeted Evaluation, Large Language Models Are Poised for Psychological Assessment},
  shorttitle = {Beyond Rating Scales},
  author = {Kjell, Oscar N.E. and Kjell, Katarina and Schwartz, H. Andrew},
  year = {2024},
  month = mar,
  journal = {Psychiatry Research},
  volume = {333},
  pages = {115667},
  issn = {01651781},
  doi = {10.1016/j.psychres.2023.115667},
  urldate = {2024-12-19},
  abstract = {In this narrative review, we survey recent empirical evaluations of AI-based language assessments and present a case for the technology of large language models to be poised for changing standardized psychological assess\- ment. Artificial intelligence has been undergoing a purported ``paradigm shift'' initiated by new machine learning models, large language models (e.g., BERT, LAMMA, and that behind ChatGPT). These models have led to un\- precedented accuracy over most computerized language processing tasks, from web searches to automatic ma\- chine translation and question answering, while their dialogue-based forms, like ChatGPT have captured the interest of over a million users. The success of the large language model is mostly attributed to its capability to numerically represent words in their context, long a weakness of previous attempts to automate psychological assessment from language. While potential applications for automated therapy are beginning to be studied on the heels of chatGPT's success, here we present evidence that suggests, with thorough validation of targeted deployment scenarios, that AI's newest technology can move mental health assessment away from rating scales and to instead use how people naturally communicate, in language.},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/QUUCPISS/Kjell et al. - 2024 - Beyond rating scales With targeted evaluation, la.pdf}
}

@article{Ladmanova2025,
  title = {Client-Identified Outcomes of Individual Psychotherapy: A Qualitative Meta-Analysis},
  shorttitle = {Client-Identified Outcomes of Individual Psychotherapy},
  author = {Ladmanov{\'a}, Michaela and {\v R}ih{\'a}{\v c}ek, Tom{\'a}{\v s} and Timulak, Ladislav and Jon{\'a}{\v s}ov{\'a}, Kl{\'a}ra and Kubantov{\'a}, Barbora and Miko{\v s}ka, Petr and Polakovsk{\'a}, Lucia and Elliott, Robert},
  year = {2025},
  month = jan,
  journal = {The Lancet Psychiatry},
  volume = {12},
  number = {1},
  pages = {18--31},
  issn = {22150366},
  doi = {10.1016/S2215-0366(24)00356-0},
  urldate = {2025-01-11},
  abstract = {Background Psychotherapy outcomes are typically measured in terms of symptom relief. However, this method might overlook important changes from clients' perspectives when they are asked to report on them. A more client-centred approach might bring a deeper understanding of psychotherapy outcomes. We aimed to evaluate the outcomes identified by clients within qualitative psychotherapy research.},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/Y63XIPXT/Ladmanová et al. - 2025 - Client-identified outcomes of individual psychothe.pdf}
}

@misc{li2022trocrtransformerbasedopticalcharacter,
  title = {{{TrOCR}}: {{Transformer-based}} Optical Character Recognition with Pre-Trained Models},
  author = {Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu},
  year = {2022},
  eprint = {2109.10282},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv}
}

@article{Likert1932,
  title = {A Technique for the Measurement of Attitudes},
  author = {Likert, R.},
  year = {1932},
  journal = {Arch. Psychol.},
  series = {22},
  volume = {140},
  number = {55}
}

@article{Lutz2022,
  title = {Measurement-{{Based}} and {{Data-Informed Psychological Therapy}}},
  author = {Lutz, Wolfgang and Schwartz, Brian and Delgadillo, Jaime},
  year = {2022},
  month = may,
  journal = {Annual Review of Clinical Psychology},
  volume = {18},
  number = {1},
  pages = {71--98},
  issn = {1548-5943, 1548-5951},
  doi = {10.1146/annurev-clinpsy-071720-014821},
  urldate = {2025-02-11},
  abstract = {Outcome measurement in the field of psychotherapy has developed considerably in the last decade. This review discusses key issues related to outcome measurement, modeling, and implementation of data-informed and measurement-based psychological therapy. First, an overview is provided, covering the rationale of outcome measurement by acknowledging some of the limitations of clinical judgment. Second, different models of outcome measurement are discussed, including pre--post, session-by-session, and higher-resolution intensive outcome assessments. Third, important concepts related to modeling patterns of change are addressed, including early response, dose--response, and nonlinear change. Furthermore, rational and empirical decision tools are discussed as the foundation for measurementbased therapy. Fourth, examples of clinical applications are presented, which show great promise to support the personalization of therapy and to prevent treatment failure. Finally, we build on continuous outcome measurement as the basis for a broader understanding of clinical concepts and data-driven clinical practice in the future.},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/WVQF2JE3/Lutz et al. - 2022 - Measurement-Based and Data-Informed Psychological .pdf}
}

@inproceedings{matero-etal-2019-suicide,
  title = {Suicide Risk Assessment with Multi-Level Dual-Context Language and {{BERT}}},
  booktitle = {Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology},
  author = {Matero, Matthew and Idnani, Akash and Son, Youngseo and Giorgi, Salvatore and Vu, Huy and Zamani, Mohammad and Limbachiya, Parth and Guntuku, Sharath Chandra and Schwartz, H. Andrew},
  editor = {Niederhoffer, Kate and Hollingshead, Kristy and Resnik, Philip and Resnik, Rebecca and Loveys, Kate},
  year = {2019},
  month = jun,
  pages = {39--44},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/W19-3005},
  abstract = {Mental health predictive systems typically model language as if from a single context (e.g. Twitter posts, status updates, or forum posts) and often limited to a single level of analysis (e.g. either the message-level or user-level). Here, we bring these pieces together to explore the use of open-vocabulary (BERT embeddings, topics) and theoretical features (emotional expression lexica, personality) for the task of suicide risk assessment on support forums (the CLPsych-2019 Shared Task). We used dual context based approaches (modeling content from suicide forums separate from other content), built over both traditional ML models as well as a novel dual RNN architecture with user-factor adaptation. We find that while affect from the suicide context distinguishes with no-risk from those with ``any-risk'', personality factors from the non-suicide contexts provide distinction of the levels of risk: low, medium, and high risk. Within the shared task, our dual-context approach (listed as SBU-HLAB in the official results) achieved state-of-the-art performance predicting suicide risk using a combination of suicide-context and non-suicide posts (Task B), achieving an F1 score of 0.50 over hidden test set labels.}
}

@inproceedings{mohammadi-etal-2019-clac-clpsych,
  title = {{{CLaC}} at {{CLPsych}} 2019: {{Fusion}} of Neural Features and Predicted Class Probabilities for Suicide Risk Assessment Based on Online Posts},
  booktitle = {Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology},
  author = {Mohammadi, Elham and Amini, Hessam and Kosseim, Leila},
  editor = {Niederhoffer, Kate and Hollingshead, Kristy and Resnik, Philip and Resnik, Rebecca and Loveys, Kate},
  year = {2019},
  month = jun,
  pages = {34--38},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/W19-3004},
  abstract = {This paper summarizes our participation to the CLPsych 2019 shared task, under the name CLaC. The goal of the shared task was to detect and assess suicide risk based on a collection of online posts. For our participation, we used an ensemble method which utilizes 8 neural sub-models to extract neural features and predict class probabilities, which are then used by an SVM classifier. Our team ranked first in 2 out of the 3 tasks (tasks A and C).}
}

@article{Radford2022,
  title = {Robust {{Speech Recognition}} via {{Large-Scale Weak Supervision}}},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  year = {2022},
  journal = {arXiv preprint arXiv: 2212.04356},
  eprint = {2212.04356},
  abstract = {We study the capabilities of speech processing systems trained simply to predict large amounts of transcripts of audio on the internet. When scaled to 680,000 hours of multilingual and multitask supervision, the resulting models generalize well to standard benchmarks and are often competitive with prior fully supervised results without the need for any dataset specific fine-tuning. When compared to humans, the models approach their accuracy and robustness. We are releasing models and inference code to serve as a foundation for further work on robust speech processing.},
  archiveprefix = {arXiv},
  langid = {english},
  file = {/Users/gabrielbonnin/Zotero/storage/4YTEQTAK/Radford et al. - Robust Speech Recognition via Large-Scale Weak Sup.pdf}
}

@misc{reimers2019sentencebertsentenceembeddingsusing,
  title = {Sentence-{{BERT}}: {{Sentence}} Embeddings Using Siamese {{BERT-networks}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2019},
  eprint = {1908.10084},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
  file = {/Users/gabrielbonnin/Zotero/storage/LN4M2MXN/Reimers und Gurevych - 2019 - Sentence-BERT Sentence embeddings using siamese B.pdf}
}

@inproceedings{Vaswani2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, L. and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-07-10},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {/Users/gabrielbonnin/Zotero/storage/YJTMXMW6/Vaswani et al. - 2017 - Attention is All you Need.pdf}
}

@book{wampold2015great,
  title = {The Great Psychotherapy Debate: {{The}} Evidence for What Makes Psychotherapy Work},
  author = {Wampold, Bruce E and Imel, Zac E},
  year = {2015},
  publisher = {Routledge}
}

@misc{warner2024smarterbetterfasterlonger,
  title = {Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference},
  author = {Warner, Benjamin and Chaffin, Antoine and Clavi{\'e}, Benjamin and Weller, Orion and Hallstr{\"o}m, Oskar and Taghadouini, Said and Gallagher, Alexis and Biswas, Raja and Ladhak, Faisal and Aarsen, Tom and Cooper, Nathan and Adams, Griffin and Howard, Jeremy and Poli, Iacopo},
  year = {2024},
  eprint = {2412.13663},
  primaryclass = {cs.CL},
  archiveprefix = {arXiv},
  file = {/Users/gabrielbonnin/Zotero/storage/2H2UWJHE/Warner et al. - 2024 - Smarter, better, faster, longer a modern bidirect.pdf}
}

@misc{WorldHealthOrganization2017,
  title = {Depression and Other Common Mental Disorders: {{Global}} Health Estimates},
  author = {{World Health Organization}},
  year = {2017}
}

@book{WorldHealthOrganization2022,
  title = {International {{Classification}} of {{Diseases}}, {{Eleventh Revision}} ({{ICD-11}})},
  author = {{World Health Organization}},
  year = {2022},
  publisher = {Author},
  address = {Geneva}
}

@inproceedings{zirikly-etal-2019-clpsych,
  title = {{{CLPsych}} 2019 Shared Task: {{Predicting}} the Degree of Suicide Risk in {{Reddit}} Posts},
  booktitle = {Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology},
  author = {Zirikly, Ayah and Resnik, Philip and Uzuner, {\"O}zlem and Hollingshead, Kristy},
  editor = {Niederhoffer, Kate and Hollingshead, Kristy and Resnik, Philip and Resnik, Rebecca and Loveys, Kate},
  year = {2019},
  month = jun,
  pages = {24--33},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  doi = {10.18653/v1/W19-3003},
  abstract = {The shared task for the 2019 Workshop on Computational Linguistics and Clinical Psychology (CLPsych`19) introduced an assessment of suicide risk based on social media postings, using data from Reddit to identify users at no, low, moderate, or severe risk. Two variations of the task focused on users whose posts to the r/SuicideWatch subreddit indicated they might be at risk; a third task looked at screening users based only on their more everyday (non-SuicideWatch) posts. We received submissions from 15 different teams, and the results provide progress and insight into the value of language signal in helping to predict risk level.}
}

@techreport{margraf2021,
	title = {DIPS Open Access 1.2: Diagnostisches Interview bei psychischen Störungen},
	author = {Margraf, {Jürgen} and Cwik, Jan Christopher and von Brachel, Ruth and Suppiger, Andrea and Schneider, Silvia},
	year = {2021},
	date = {2021},
	doi = {10.46586/rub.172.149},
	url = {http://dx.doi.org/10.46586/rub.172.149}
}
